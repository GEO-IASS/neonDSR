\chapter{Introduction}%
\label{chapter:Introduction}

Understanding the dynamics of ecological structures is very important in determining how climate, %CO\textsuperscript{2} emission, 
land cover %(water resources, desertification)
, fire hazards, and biodiversity evolve. Precision study of plant species is of high environmental and economical impacts which is only possible through geo-mapping the distribution of plant species abundances at ecological scale. Large scale study of ecological domains has been made possible through spaceborne or airborne campaigns utilizing remote sensing technologies such as \textit{(multi/hyper)-spectral} and \textit{LiDAR}. In this project we focus on airborne hyperspectral and LiDAR data. Each campaign covering tens of acres of land can generate terra-bytes of data depending on measurement resolution (large volume). On the other hand, apart from state-of-the-art machine learning algorithms, there is a great wealth of expert ecological knowledge covering a whole variety of domains (along with their in-ground associated data) that can be used to enhance species mapping that is not being used and is left for ecological scientists for manual interpretation (data variety). Furthermore, data is being generated at faster pace day after day as technology becomes more afordable. After satellite sensors, airborne sensors came into place and now as airborne is still costly there is a surge of interest towards more affordable drone campaigns \citep{zhou2009foreword}. So we are facing data being generated at unprecedented rates (data velocity). The final aspect is verasity: imperfect sensors, non-standardized measurements, atmosphere impacts (clouds, humidity, aerosols) and et cetera all create uncertainities that need to be accounted for. Velocity, verasity, volume, and variety are the four V's that indicate ecology is stepping into the realm of "big data"\citep{hampton2013big, soranno2014macrosystems}.

\section{Remote Sensing}

From an ecological point of view, there are two types of remote sensing approaches: active and passive. \textit{Passive} remote sensing uses sunlight as the source of energy and sensors captures the intensity of light being reflected from earth's surface. Light intensity measurements happens at various wavelengths; if a few (usually 3 to 10) relatively broad wavelength bands are captured it is called multi-spectral. If light intensity at dozens to hundreds of narrow band signals are collected it is called hyperspectral. \textit{Active} remote sensing on the other hand uses laser light emission as its source of energy and captures the intensity of returned signals. LiDAR is a popular active remote sensing technology. Below we explain each in more details:



\subsection{Hyperspectral}

\begin{figure}[b!]
  \centering
    \includegraphics[scale=0.22]{images/spectrometer.eps}
    \caption[Imaging spectrometer schematic diagram]{Schematic diagram of the basic elements of an imaging spectrometer where $\lambda$ is the wavelength \citep{smith2006introduction}.}
    \label{fig:Imaging spectrometer}
\end{figure}

Spectrometers measure the amount of light reflected from surface materials: An optical dispersing element (like a prism) refracts the received light into its constituent spectrums and the energy in each band range is measured by a separate detector. Bands can be as narrow as $0.01 \mu m$ over a wide wavelength range of typically $0.4 \mu m$ to $2.5 \mu m$. Figure~\ref{fig:Imaging spectrometer} shows the basic components of an imaging spectrometer.

Raw sensor readings (digital number) can be affected by light source conditions, sensor, atmosphere, and surface material. Raw data which is a unit-less light intensity measure is then calibrated into radiance which has a  physically meaningful unit through applying a gain and offset to the pixel values. It essentially means how much light the instrument ''sees'' from the object being observed. Some reference materials like a pure white or pure black sheets can be used in this process. After adjustments for sensor, atmospheric, and terrain effects are applied, pixel reflectance value is calculated which is the proportion of the radiation striking a surface to the radiation reflected off of it. Reflectance demonstrates light abroption features of the surface material and can be compared with field or laboratory reflectance spectra in order to recognize and map surface materials such as particular types of vegetation or diagnostic minerals associated with ore deposits. Reflectance varies with wavelength for most materials because energy at certain wavelengths is scattered or absorbed to different degrees \citep{smith2006introduction}. In this project we deal with reflectance values and refer the reader to \citep{varshney2004advanced} for more details on how to compute reflectance values.


\begin{figure}[t!]
  \centering
    \includegraphics[scale=0.45]{images/reflectanceAsIndicator.eps}
    \caption[Some reflectance examples]{Some reflectance examples as how reflectance of different material show different absroption features at differnet bands. \citep{smith2006introduction}.}
    \label{fig:Some reflectance examples}
\end{figure}

Figure~\ref{fig:Some reflectance examples} shows some example materials when observed through an spectrometer. In vegetations, chlorophyll and some leaf pigments show high absorptions in blue and red ranges and not so much in green; therefore our eyes see vegetation as green. We can see this as a small peak in green compared to other visible wavelength range. From red to near infrared there is a sharp rise known as \textit{red edge} up to a value of about 50\% for some plants. High values in the near-infrared region is mainly due to internal cellular structure of leaves which differs significantly across species but can also be different in a single specie due to plant stress. High reflectance in near-infrared can interact with other leaves in the canopy and therefore its sensor readings can be dependent on canopy structure as well. Beyond  $1.3 \mu m$ reflectance decreases with increasing wavelength, except for two pronounced water absorption bands near $1.4 \mu m$ and  $1.9 \mu m$. At the end of the growing season leaves lose water and chlorophyll. Near infrared reflectance decreases and red reflectance increases, creating the yellow, brown, and red leaf colors of autumn \citep{smith2006introduction}.

One note worthy concept is the issue of mixing. Pixel size can be large based on the distance between the sensor and target; this makes it likely that more than one material contribute to the signal received by the sensor. The received signal is called a \textit{composite} or \textit{mixed} signal and the ''pure'' signal that contribute to the mixture are called \textit{endmember} signal. The mixture model can be either linear or non-linear. Linear mixture happens at macro-scale where we have for example a large patch of land beside a large patch of vegetation. If we denote the received signal, land, and vegetation as $S$,$L$, and $V$ respectively the mixture model could be  $S=60\%L+40\%V$. Linear mixture of three endmembers can easily be shown to fall within the triangle where its vertices are endmember spectra. Variations in lighting can be included directly in the mixing model by defining a ''shade'' endmember (shade, deep water body, dark asphalt or etc) that can approximate light changes and mix with the actual material spectra. Non-linear mixture model on the other hand is more intimate and happens at micro-scale. For example in a microscopic mixture of mineral particles found in soil, a single photon can interacts with more than one material, therefore resulting in a non-linear mixture \citep{keshava2003survey, bioucas2012hyperspectral, dobigeon2014nonlinear}.


\subsection{LiDAR}

Light Detection And Ranging (LiDAR) is a form of active remote sensing where a laser beam is used to detect points on earth. LiDAR sensor is mounted on an airplane and it keeps swiping earth surface as the plane moves forward. By knowing parameters of the LiDAR sensor itself (tilt angle of the pulse), plane GPS coorinates, and Inertial Measurement Unit (IMU) coordinates (heading, pitch and roll) and the speed of light, the exact coorinate of each point reading is calculated. LiDAR scans at pulse rates of over 300,000 pulses per second (300 kilohertz) depending on sensor technology. By subtracting plane altitude from the distance that laser has traveled we get the ground elevation.  Using some filtering techniques points on the ground are classified from points above the ground and this yeilds the height of the objects on the ground. Figure~\ref{fig:lidar} (A) demonstrates a schematic view of a LiDAR flightand its parameters \citep{schmid2008lidar}.


\begin{figure}[b!]
  \begin{center}
    \centering
    \mbox{
      \subfigure[]{\fbox{\epsfig{file=images/lidarPlane.eps, scale=0.6}}} \quad
      \subfigure[]{\fbox{\epsfig{file=images/lidarMultipleReturns.eps, scale=0.38}}} \quad
     }
    
    \caption[Schematic view of a LiDAR flight]{A) Schematic view of a LiDAR flight: GPS coordinates, IMU coordinates, and tilt angle of pulse together determine the position of the point on the ground (Source: Ohio Department of Transportation). B) Return waveform of a single LiDAR pulse both in its actual continuous form and its 3 discrete records (crown, understory, and ground) each as a point in the point cloud \citep{fernandez2014now}.}
    \label{fig:lidar}
  \end{center}
\end{figure}

%\begin{figure}[b!]
%  \centering
%    \includegraphics[scale=0.45]{images/lidarPlane.eps}
%    \caption[Schematic view of a LiDAR flight]{Schematic view of a LiDAR flight: GPS coordinates, IMU coordinates, and tilt angle of pulse together determine the position of the point on the ground (Source: Ohio Department of Transportation).}
%    \label{fig:lidar plane}
%\end{figure}

Each LiDAR pulse can have multiple returns depending if it can penetrate through and how much signal intensity is reflected back. Figure~\ref{fig:lidar} (B) shows how each LiDAR pulse can have multiple return values. Unlike hyperspectral imaging, LiDAR returns a long list of points \textless x (latitude), y (longtitude), z (elevation), i (intensity), n (number of this return for given pulse), d (direction of scan), e (edge of flight line), t (time)\textgreater. For lidar usually green or near infrared is used as it has high reflectance from vegetation.

%\begin{figure}[b!]
%  \centering
%    \includegraphics[scale=0.30]{images/lidarMultipleReturns.eps}
%    \caption[Multiple returns of a LiDAR pulse]{Multiple returns of a LiDAR pulse \citep{fernandez2014now}.}
%    \label{fig:lidar multiple returns}
%\end{figure}



\section{Knowledge Sources}

Ecological domain features a large variety of concepts from microbial-scale to soil, plants, animals, geology, climate, and all in between. This shows the wealth of knowledge and inter-related aspects of bio-diversity that needs to be taken into account to be able to have a comprehensive understanding of environment. This information can be found in a variety of sources: Here we would like to introduce some major peer-reviewed data repositories available online: TRY database (datasets covering a wide variety of biomes and geographic areas), TraitNet (Trait databases), USGS Land Cover (planetary diversity, trends, and aquatics), http://ecologicaldata.org and http://datadryad.org (community-driven datasets), DataOne and EarthCube (NSF-funded data archiving resources for ecological, environmental and geosciences data products), iPlant/iAnimal (gene level data portals) and NEON with over 120 high level data products (apart from hundreds of low-level data types) (\citep{keller2010neon}, \citep{lunch2014neonLevel}). There are also crowd-sourced datasets available such as UF’s iDigBio, BudBurst or Citizen Science initiative platforms.

Besides well-structured data, there is a great wealth of knowledge in textual scientific content that is untapped. Resources such as the Silvics of North America \citep{burns1990silvics}, local field guides such as \citep{inventory1990guide, lillybridge1995field}, any of the thousands of peer-reviewed academic journal or conference publications and etc are good sources of knowledge.

There are projects that share the same concept but tackle different domains, the most famous of which is GeoDeepDive from Hazy group at Stanford. GeoDeepDive focuses on geographical domain and collects knowledge from thousands of scientific papers.

\section{Proposed Work}

Based on the domain of information sources available in ecological sciences we propose a system architecture to capture the intrinsic nature of ''big data'' to enhance species classification in remote sensing applications. We propose to use the concept of probabilistic knowledge bases to contain knowledge sources as a set of probabilistic rules that we can perform inference on. The architecture will be scalable able to handle millions of facts and rules about various concept of ecological sciences. We also propose to use deep learning to act as a semi-supervised machine learning algorithm. We pretrain the network on all the pixels available both labled and unlabled and then fine-tune its weights using the few labeled data that might be available. In the following chapter we describe the details of our architecture in detail. 

\section{Proposal Structure}

In Chapter \ref{chapter:Introduction} we provide an over view of the problem domain. In Chapter \ref{chapter:Species Classification} we provide our preliminary results on various remote sensing species classification techniques. Chapter \ref{chapter:Information Extraction from Text} provides the details on our information extraction architecture from plain text resources. In Chapter \ref{chapter:Big Data Techniques} we elaborate state-of-the-art techniques for information extraction and deep learning architectures. Finally we descibe the details of our design for the proposed architecture using both probabilistic knowledge bases and deep learning architectures in Chapter \ref{chapter:Proposed Work}. 



% Mapping the spatial distribution of plant species in savannas provides insight into the roles of competition, fire, herbivory, soils and climate in maintaining the biodiversity of these ecosystems. 
 
% Savannas harbor spatially complex assemblages of vegetation that are mediated by an array of biotic and abiotic factors including plant competition, fire, herbivory, soils and climate [1–4]. Mapping the distribution of species abundances across spatial scales relevant to these processes is requisite to understanding their role in shaping and maintaining savanna biodiversity.
 
%%% Invasive plant species can change entire habitats by penetrating the native canopy and eventually replacing it [1]. At times, fundamental ecosystem processes such as nitrogen (N) cycling as well as disturbance regimes such as fire frequency are altered by the introduced species, resulting in a major change in biological diversity and ecosystem functioning [2].
 
% Effective management of introduced species starts with monitoring and mapping, which is a central component of the biological diversity protection programs of many government agencies and non- governmental organizations worldwide [3]. Remote detection and mapping of biodiversity and invasive species from airborne or spaceborne instruments is promising (review by [4]), but  operational approaches are lacking because of our limited biophysical understanding of when remotely sensed signatures indicate the presence of unique species—native or invasive—within and across ecosystems. The spectra express the biochemical and structural properties of the vegetation, but translating that to species composition requires an increased understanding of the """""""spectral separability""""""""" of species at different levels of ecological and taxonomic aggregation.
 
 
%%%% Tropical forests store a large proportion of terrestrial carbon. For example, Dixon et al. (1994) estimated that low-latitude tropical forests contain 59\% and 27\% of carbon stored in global forest vegetation and soil pools, respectively. There still remains considerable uncertainty in global and regional estimates of carbon stocks and dynamics. 
